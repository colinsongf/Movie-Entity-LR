{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.43946092  9.35429997  0.58873786]]\n",
      "The end is the beginning is the end.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from sklearn.linear_model import LogisticRegression as LogiReg\n",
    "from sklearn.model_selection import cross_val_score as crossVal\n",
    "\n",
    "DATA_PATH = \"../data/\"\n",
    "OUTPUT_PATH = \"../output/\"\n",
    "\n",
    "\n",
    "# team member:\n",
    "def parse_dur(timestr):\n",
    "    \"\"\"\n",
    "    Parse various time string into value in minutes\n",
    "    timestr: containing hour, minute, and seconds\n",
    "    deliminator does not matter\n",
    "    abbreviations are okay, as long as it contains\n",
    "    h for hour, m for minute, s for second\n",
    "\n",
    "    :param timestr: containing hour, minute, and secondsd; eliminator does not matter abbreviations are okay,\n",
    "                    as long as it contains h for hour, m for minute, s for second.\n",
    "    :return: integer, rounded to the nearest minute\n",
    "    \"\"\"\n",
    "    if isinstance(timestr, str):\n",
    "        hrs = re.findall(r'[0-9]+[\\s]*h', timestr)\n",
    "        mins = re.findall(r'[0-9]+[\\s]*m', timestr)\n",
    "        secs = re.findall(r'[0-9]+[\\s]*s', timestr)\n",
    "        tarray = [0, 0, 0]  # Default 0\n",
    "        tscale = [60, 1, 1 / 60]  # Scale to Minutes\n",
    "        tinmins = 0  # Default 0\n",
    "        for tind, tstr in enumerate([hrs, mins, secs]):\n",
    "            if len(tstr) != 0:\n",
    "                tarray[tind] = int(re.findall(r'[0-9]+', tstr[0])[0])\n",
    "                tinmins += tarray[tind] * tscale[tind]\n",
    "        return round(tinmins)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def read_amazon(amazonfile):\n",
    "    \"\"\"Just pandas read csv with fixed arguments\"\"\"\n",
    "    df_read = pd.read_csv(amazonfile, na_values=['NA'], engine='python', index_col=0,\n",
    "                          usecols=[\"id\", \"time\", \"director\", \"star\"])\n",
    "    return df_read\n",
    "\n",
    "\n",
    "def read_rottmt(rottmtfile):\n",
    "    \"\"\"Just pandas read csv with fixed arguments\"\"\"\n",
    "    df_read = pd.read_csv(rottmtfile, na_values=['NA'], engine='python', index_col=0,\n",
    "                          usecols=[0, 1, 2, 4, 5, 6, 7, 8, 9])\n",
    "    return df_read\n",
    "\n",
    "\n",
    "def liststr_remover(listin, str_format):\n",
    "    \"\"\"Maybe useful later. Not sure yet.\n",
    "    \"\"\"\n",
    "    listout = []\n",
    "    for element in listin:\n",
    "        if element != str_format:\n",
    "            listout.append(element)\n",
    "    return listout\n",
    "\n",
    "\n",
    "def entry_parser(ent_amz, ent_tmt):\n",
    "    \"\"\" Further parse formatted entries into values\n",
    "\n",
    "    Current mechanism: parse duration, director, and stars into scores, respectively;\n",
    "    Duration: ratio in domain [0,1]; if duration seems strange, 0.5 is forced.\n",
    "    Director: Fuzzy token set match\n",
    "    Stars: Average score of element-wise list match\n",
    "    e.g. For ['John Smith', 'Mary Jane', 'Ulysses Grant'] and\n",
    "    ['Jane Smith', 'Jason Bourne', 'Ulysses S. Grant', 'Jon Doe', 'Maria June', 'Motoko Kusanagi']\n",
    "    iterat through the shorter list, find the best token set match, and find the average score.\n",
    "\n",
    "    :param ent_amz: [Duration (str), Director (str), Stars (str)]\n",
    "    :param ent_tmt: [Duration (str), Director (str), Stars * 6 (multiple)]\n",
    "    :return: parsed scores [X_dur, X_director, X_stars]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Both have duration at their first column\n",
    "    dur_amz = parse_dur(ent_amz[0])\n",
    "    dur_tmt = parse_dur(ent_tmt[0])\n",
    "    if dur_amz >= 10 and dur_tmt >= 10:\n",
    "        # Duration ratio: 0 to 1, automatically normalized\n",
    "        dur_ratio = min(dur_amz, dur_tmt) / max(dur_amz, dur_tmt)\n",
    "    else:  # abnormal duration values\n",
    "        dur_ratio = 0.5  # Force the duration ratio to be 0.5\n",
    "\n",
    "    # column 2. Normalize to 1 (Fuzzywuzzy scores 0 to 100)\n",
    "    director_ratio = fuzz.token_set_ratio(str(ent_amz[1]), str(ent_tmt[1])) / 100\n",
    "\n",
    "    # For amazon.csv, stars are grouped in one string\n",
    "    str_amz = str(ent_amz[2])\n",
    "\n",
    "    # For rotten_tomatoes.csv, each star is in one column, with blank ones marked as nan\n",
    "    lstrna_tmt = ent_tmt[2:]\n",
    "    # Convert them to comparable formats\n",
    "    lstr_amz = [xstr.strip() for xstr in str_amz.split(',')]\n",
    "    lstr_amz = sorted(lstr_amz)\n",
    "    # Remove the nan's\n",
    "    # this syntax only works in Python3\n",
    "    lstr_tmt = list(filter(None.__ne__, lstrna_tmt))\n",
    "    lstr_tmt = sorted(np.str(lstr_tmt))\n",
    "\n",
    "    # Find the shorter list\n",
    "    if len(lstr_amz) <= len(lstr_tmt):\n",
    "        lstr_short = lstr_amz\n",
    "        lstr_long = lstr_tmt\n",
    "    else:\n",
    "        lstr_short = lstr_tmt\n",
    "        lstr_long = lstr_amz\n",
    "    ratio_total = 0\n",
    "    n_entries = 0\n",
    "\n",
    "    # Iterate through to find matching names\n",
    "    for xstr in lstr_short:\n",
    "        ratio_total += process.extractOne(xstr, lstr_long, scorer=fuzz.token_set_ratio)[1]\n",
    "        n_entries += 1\n",
    "\n",
    "    # Average & Normalize\n",
    "    star_ratio = ratio_total / n_entries / 100.0\n",
    "\n",
    "    return [dur_ratio, director_ratio, star_ratio]\n",
    "\n",
    "\n",
    "# Main Process Begins\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Change this to your directory housing all the csv files.\n",
    "# os.chdir(\"C:/Users/cydru/Documents/W4121/W4121_EnRes\")\n",
    "\n",
    "# Read the training set first\n",
    "# coz it's easy\n",
    "df_train = pd.read_csv(DATA_PATH + 'train.csv', na_values=['NA'], engine='python', index_col=None)\n",
    "trainlist_amz = list(df_train.iloc[:, 0])\n",
    "trainlist_tmt = list(df_train.iloc[:, 1])\n",
    "trainlist_ans = list(df_train.iloc[:, 2])\n",
    "\n",
    "# read the messy data files\n",
    "df_rottmt = read_rottmt(DATA_PATH + 'rotten_tomatoes.csv')\n",
    "df_amazon = read_amazon(DATA_PATH + 'amazon.csv')\n",
    "# Extract only relevant entries\n",
    "# In this case, training entries\n",
    "sl_amazon = df_amazon.loc[trainlist_amz, :]\n",
    "sl_rottmt = df_rottmt.loc[trainlist_tmt, :]\n",
    "l_train = len(trainlist_ans)\n",
    "\n",
    "# Constructing the trainng input\n",
    "xmat = list([])\n",
    "# # Separate the abnormally formated entries from \"normal\" ones\n",
    "# abnormals = list([])\n",
    "for itentry in range(l_train):\n",
    "    # Extract entry\n",
    "    entry_amz = list(sl_amazon.iloc[itentry, :])\n",
    "    entry_tmt = list(sl_rottmt.iloc[itentry, :])\n",
    "    # Calculate and Record\n",
    "    xmat.append(entry_parser(entry_amz, entry_tmt))\n",
    "\n",
    "# Convert to ndarray with numpy for inputting into sklearn\n",
    "xmat = np.array(xmat)\n",
    "yvec = np.array(trainlist_ans)\n",
    "\n",
    "# Cross-validation to find best regulatory term\n",
    "Cvec = np.power([2] * 30, range(30))\n",
    "Scores = np.arange(30, dtype=np.float64)\n",
    "for ind, Cval in enumerate(Cvec):\n",
    "    cross_scores = crossVal(LogiReg(C=Cval), xmat, yvec, scoring='accuracy', cv=20)\n",
    "    Scores[ind] = cross_scores.mean()\n",
    "Cbest = Cvec[np.argmax(Scores, axis=0)]\n",
    "model = LogiReg(C=Cbest)\n",
    "model = model.fit(xmat, yvec)\n",
    "print(model.coef_)  # For our information\n",
    "\n",
    "# Testing Procedure: test.csv\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "df_test = pd.read_csv(DATA_PATH + 'test.csv', na_values=['NA'], engine='python', index_col=None)\n",
    "testlist_amz = list(df_test.iloc[:, 0])\n",
    "testlist_tmt = list(df_test.iloc[:, 1])\n",
    "st_amazon = df_amazon.loc[testlist_amz, :]\n",
    "st_rottmt = df_rottmt.loc[testlist_tmt, :]\n",
    "l_test = len(testlist_amz)\n",
    "xmat_test = list([])\n",
    "for itentry in range(l_test):\n",
    "    # Extract entry\n",
    "    entry_amz = list(st_amazon.iloc[itentry, :])\n",
    "    entry_tmt = list(st_rottmt.iloc[itentry, :])\n",
    "    # Calculate and Record\n",
    "    xmat_test.append(entry_parser(entry_amz, entry_tmt))\n",
    "xmat_test = np.array(xmat_test)\n",
    "yvec_predict = model.predict(xmat_test)\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Write to csv\n",
    "goldframe = pd.DataFrame(data=yvec_predict, index=None, columns=[\"gold\"])\n",
    "goldframe.to_csv(OUTPUT_PATH + 'gold.csv', sep=',', index=False, index_label=False)\n",
    "\n",
    "# Testing Procedure: holdout.csv\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "df_test = pd.read_csv(DATA_PATH + 'holdout.csv', na_values=['NA'], engine='python', index_col=None)\n",
    "testlist_amz = list(df_test.iloc[:, 0])\n",
    "testlist_tmt = list(df_test.iloc[:, 1])\n",
    "st_amazon = df_amazon.loc[testlist_amz, :]\n",
    "st_rottmt = df_rottmt.loc[testlist_tmt, :]\n",
    "l_test = len(testlist_amz)\n",
    "xmat_test = list([])\n",
    "for itentry in range(l_test):\n",
    "    # Extract entry\n",
    "    entry_amz = list(st_amazon.iloc[itentry, :])\n",
    "    entry_tmt = list(st_rottmt.iloc[itentry, :])\n",
    "    # Calculate and Record\n",
    "    xmat_test.append(entry_parser(entry_amz, entry_tmt))\n",
    "xmat_test = np.array(xmat_test)\n",
    "yvec_predict = model.predict(xmat_test)\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Write to csv\n",
    "goldframe = pd.DataFrame(data=yvec_predict, index=None, columns=[\"gold\"])\n",
    "goldframe.to_csv(OUTPUT_PATH + 'gold2.csv', sep=',', index=False, index_label=False)\n",
    "\n",
    "print('The end is the beginning is the end.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
